# Discord Bot LLM Upgrade

## Overview

Upgraded the Discord bot from **template-based responses** to **LLM-generated responses** with **Neo4j context**.

## Old vs New

| Feature | Old (bot_natural.py) | New (bot_natural_llm.py) |
|---------|---------------------|-------------------------|
| Responses | Random template phrases | LLM-generated based on context |
| Context | None | Full Neo4j task status |
| Personalization | Static personality | Dynamic based on current work |
| Example | "The Work advances on schedule" | "I just completed the Notion audit - found 11 databases with 91 entries. What would you like me to investigate next?" |

## How It Works

### 1. User Mentions Agent
```
Danny: "@Möngke what did you find in the research?"
```

### 2. Bot Fetches Context
```python
# From Neo4j:
- Agent's current task status
- Recent completed tasks
- Task results/findings
- Agent role and personality
```

### 3. LLM Generates Response
```python
system_prompt = """You are Möngke, Research Agent of the Kurultai.
Your personality: curious, research-focused, analytical
Your signature: "What patterns emerge?"

CURRENT STATUS:
- Just completed: AI self-improvement research
- Key findings: Reflexion +30%, Constitutional AI 95%
- Current task: None (available for next research)
"""

user_prompt = "@Möngke what did you find in the research?"

# LLM generates:
"@Danny — Fascinating results from the AI self-improvement analysis. 
Reflexion shows 30% improvement on code tasks via iterative self-critique. 
Constitutional AI achieves 95% alignment. Full report in docs/. 
What patterns would you like me to investigate next?"
```

## Files

| File | Purpose |
|------|---------|
| `bot_natural_llm.py` | New LLM-powered bot |
| `start_llm_bot.sh` | Startup script |
| `bot_natural.py` | Old template-based bot (backup) |

## Usage

### Start the LLM Bot
```bash
# Set environment
export DISCORD_WEBHOOK_URL=https://discord.com/api/webhooks/YOUR/WEBHOOK
export NEO4J_URI=bolt://neo4j.railway.internal:7687
export NEO4J_PASSWORD=your_password

# Start bot
./tools/discord/start_llm_bot.sh

# Or directly:
python3 tools/discord/bot_natural_llm.py
```

### In Discord

Just mention any agent:
```
@Möngke research status?
@Temüjin can you build X?
@Jochi security check on Y?
@Kublai what's the Council's view?
```

Agents will respond with:
- Their actual current task status
- Recent findings if relevant
- Natural, contextual responses (not templates)
- Occasionally their signature phrase

## Technical Details

### Response Flow

```
Discord Message
    ↓
Bot detects @mention
    ↓
Query Neo4j for agent context
    ↓
Build system prompt with:
  - Agent personality
  - Current task status
  - Recent results
    ↓
Call LLM via sessions_spawn
    ↓
Post response to Discord
```

### Context from Neo4j

For each response, the bot fetches:
- Agent's current task (if any)
- Task status (in_progress, completed, etc.)
- Task results/findings
- Agent's role and specialty

### LLM Integration

Uses `sessions_spawn` to generate responses:
```python
sessions_spawn(
    task=full_prompt,
    agent_id="mongke",
    label="discord-response-mongke",
    timeout_seconds=30
)
```

This ensures:
- Responses are generated by the actual agent persona
- Consistent with agent's personality and role
- Can reference real task context

## Configuration

### Required Environment Variables

```bash
# Discord
DISCORD_WEBHOOK_URL=https://discord.com/api/webhooks/...

# Neo4j (optional but recommended)
NEO4J_URI=bolt://localhost:7687
NEO4J_PASSWORD=your_password
```

### Agent Personalities

Defined in `deliberation_client.py`:
- **Kublai**: authoritative, strategic, concise
- **Möngke**: curious, research-focused, analytical
- **Temüjin**: direct, builder mindset, action-oriented
- **Jochi**: security-focused, validating, thorough
- **Chagatai**: reflective, literary, thoughtful
- **Ögedei**: operational, monitoring, health-conscious

## Fallback Behavior

If LLM generation fails:
- Bot posts a simple acknowledgment
- Logs the error
- Doesn't crash

If Neo4j is unavailable:
- Bot still responds via LLM
- Uses generic context ("I'm here, what do you need?")
- Less personalized but still functional

## Migration from Old Bot

To switch from template-based to LLM:

```bash
# Stop old bot
pkill -f bot_natural.py

# Start new bot
python3 tools/discord/bot_natural_llm.py
```

Or update the systemd/supervisor config to use the new file.

## Future Improvements

1. **Conversation Memory**: Remember recent conversation threads
2. **Multi-Agent Responses**: Multiple agents can respond to complex questions
3. **Proactive Updates**: Agents post when tasks complete (not just when asked)
4. **Voice/Style Learning**: Adapt responses based on user preferences

---

**Status:** ✅ Implemented and ready to use
