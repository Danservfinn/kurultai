#!/usr/bin/env python3
"""
Dynamic Task Generation System - Kurultai v2.0

Monitors research findings, knowledge gaps, and system events to automatically
generate actionable tasks. Spawns agents based on findings and detects knowledge
 gaps that require research.

Author: Kurultai v2.0
Date: 2026-02-10
"""

import os
import sys
import json
import hashlib
import asyncio
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Set, Tuple
from dataclasses import dataclass, field
from enum import Enum

# Add parent directory to path
sys.path.insert(0, os.path.dirname(os.path.dirname(__file__)))

from kurultai.kurultai_types import TaskStatus, DeliverableType


class GapType(Enum):
    """Types of knowledge gaps that can trigger task generation."""
    MISSING_DOCUMENTATION = "missing_documentation"
    INCOMPLETE_RESEARCH = "incomplete_research"
    ORPHANED_CONCEPT = "orphaned_concept"
    OUTDATED_INFORMATION = "outdated_information"
    UNCONNECTED_TOPIC = "unconnected_topic"
    CONTRADICTORY_DATA = "contradictory_data"
    LOW_CONFIDENCE = "low_confidence"
    ACTIONABLE_FINDING = "actionable_finding"


class TaskTrigger(Enum):
    """Events that can trigger dynamic task generation."""
    RESEARCH_COMPLETED = "research_completed"
    KNOWLEDGE_GAP_DETECTED = "knowledge_gap_detected"
    AGENT_ERROR_PATTERN = "agent_error_pattern"
    USER_REQUEST_IMPLICIT = "user_request_implicit"
    SYSTEM_ANOMALY = "system_anomaly"
    SCHEDuled_ANALYSIS = "scheduled_analysis"
    EXTERNAL_FEED = "external_feed"


@dataclass
class KnowledgeGap:
    """Represents a detected knowledge gap."""
    gap_type: GapType
    description: str
    affected_nodes: List[str] = field(default_factory=list)
    confidence: float = 0.5
    priority: str = "medium"
    suggested_action: str = ""
    metadata: Dict[str, Any] = field(default_factory=dict)
    detected_at: datetime = field(default_factory=datetime.now)
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "gap_type": self.gap_type.value,
            "description": self.description,
            "affected_nodes": self.affected_nodes,
            "confidence": self.confidence,
            "priority": self.priority,
            "suggested_action": self.suggested_action,
            "detected_at": self.detected_at.isoformat()
        }


@dataclass
class GeneratedTask:
    """A task generated by the dynamic task generator."""
    id: str
    title: str
    description: str
    deliverable_type: DeliverableType
    priority: str
    triggered_by: TaskTrigger
    source_gap: Optional[KnowledgeGap] = None
    required_agents: List[str] = field(default_factory=list)
    estimated_duration: int = 15  # minutes
    auto_assign: bool = True
    context: Dict[str, Any] = field(default_factory=dict)
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "id": self.id,
            "title": self.title,
            "description": self.description,
            "deliverable_type": self.deliverable_type.value,
            "priority": self.priority,
            "triggered_by": self.triggered_by.value,
            "required_agents": self.required_agents,
            "estimated_duration": self.estimated_duration,
            "auto_assign": self.auto_assign
        }


class DynamicTaskGenerator:
    """
    Monitors research findings and system state to dynamically generate tasks.
    
    Features:
    - Detects knowledge gaps from Neo4j graph analysis
    - Monitors research outputs for actionable items
    - Auto-creates tasks when confidence thresholds are met
    - Spawns appropriate agents based on task type
    """
    
    def __init__(self, driver):
        self.driver = driver
        self.recent_gaps: List[KnowledgeGap] = []
        self.generation_history: List[Dict] = []
        
        # Configuration thresholds
        self.confidence_threshold = 0.7
        self.min_gap_age_hours = 1  # Don't regenerate for same gap within 1 hour
        self.max_tasks_per_cycle = 5
        
    def generate_task_id(self, prefix: str = "dtg") -> str:
        """Generate unique task ID."""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        random_suffix = hashlib.md5(str(datetime.now()).encode()).hexdigest()[:6]
        return f"{prefix}_{timestamp}_{random_suffix}"
    
    def detect_knowledge_gaps(self) -> List[KnowledgeGap]:
        """
        Analyze Neo4j graph to detect knowledge gaps.
        
        Returns list of detected gaps that warrant task generation.
        """
        gaps = []
        
        with self.driver.session() as session:
            # 1. Find concepts with missing documentation
            result = session.run('''
                MATCH (c:Concept)
                WHERE c.documentation IS NULL 
                   OR c.documentation = ''
                   OR size(c.documentation) < 200
                OPTIONAL MATCH (c)-[:HAS_RESEARCH]->(r:Research)
                WITH c, count(r) as research_count
                WHERE research_count < 3
                RETURN c.id as id, c.name as name, 
                       coalesce(size(c.documentation), 0) as doc_length,
                       research_count
                ORDER BY research_count ASC
                LIMIT 20
            ''')
            
            for record in result:
                gap = KnowledgeGap(
                    gap_type=GapType.MISSING_DOCUMENTATION,
                    description=f"Concept '{record['name']}' has insufficient documentation ({record['doc_length']} chars)",
                    affected_nodes=[record['id']],
                    confidence=0.8 if record['doc_length'] < 50 else 0.6,
                    priority="high" if record['doc_length'] < 50 else "medium",
                    suggested_action=f"Research and document concept: {record['name']}"
                )
                gaps.append(gap)
            
            # 2. Find orphaned concepts (no relationships)
            result = session.run('''
                MATCH (c:Concept)
                WHERE NOT (c)--()
                  AND (c.created_at IS NULL 
                       OR c.created_at < datetime() - duration('P1D'))
                RETURN c.id as id, c.name as name, c.created_at as created
                ORDER BY c.created_at ASC
                LIMIT 15
            ''')
            
            for record in result:
                gap = KnowledgeGap(
                    gap_type=GapType.ORPHANED_CONCEPT,
                    description=f"Concept '{record['name']}' is orphaned with no connections",
                    affected_nodes=[record['id']],
                    confidence=0.9,
                    priority="medium",
                    suggested_action=f"Connect orphaned concept to related knowledge: {record['name']}"
                )
                gaps.append(gap)
            
            # 3. Find topics with low connectivity (sparse knowledge)
            result = session.run('''
                MATCH (t:Topic)
                OPTIONAL MATCH (t)-[:RELATED_TO]-(other)
                WITH t, count(other) as connection_count
                WHERE connection_count < 2
                OPTIONAL MATCH (t)<-[:ABOUT]-(r:Research)
                WITH t, connection_count, count(r) as research_count
                WHERE research_count < 2
                RETURN t.id as id, t.name as name, 
                       connection_count, research_count
                ORDER BY connection_count ASC
                LIMIT 15
            ''')
            
            for record in result:
                gap = KnowledgeGap(
                    gap_type=GapType.UNCONNECTED_TOPIC,
                    description=f"Topic '{record['name']}' has sparse connections ({record['connection_count']} links)",
                    affected_nodes=[record['id']],
                    confidence=0.75,
                    priority="medium",
                    suggested_action=f"Research connections for topic: {record['name']}"
                )
                gaps.append(gap)
            
            # 4. Find outdated research (> 30 days old)
            result = session.run('''
                MATCH (r:Research)
                WHERE r.created_at < datetime() - duration('P30D')
                  AND (r.verified_at IS NULL 
                       OR r.verified_at < datetime() - duration('P30D'))
                RETURN r.id as id, r.topic as topic, 
                       r.created_at as created,
                       r.verified_at as verified
                ORDER BY r.created_at ASC
                LIMIT 10
            ''')
            
            for record in result:
                gap = KnowledgeGap(
                    gap_type=GapType.OUTDATED_INFORMATION,
                    description=f"Research on '{record['topic']}' may be outdated (last verified: {record['verified']})",
                    affected_nodes=[record['id']],
                    confidence=0.6,
                    priority="low",
                    suggested_action=f"Verify and update research: {record['topic']}"
                )
                gaps.append(gap)
            
            # 5. Find low confidence nodes
            result = session.run('''
                MATCH (n)
                WHERE n.confidence IS NOT NULL 
                  AND n.confidence < 0.4
                  AND (n.tombstone IS NULL OR n.tombstone = false)
                RETURN n.id as id, labels(n) as labels, 
                       n.name as name, n.confidence as confidence
                ORDER BY n.confidence ASC
                LIMIT 15
            ''')
            
            for record in result:
                gap = KnowledgeGap(
                    gap_type=GapType.LOW_CONFIDENCE,
                    description=f"Low confidence {record['labels'][0]} '{record['name']}' ({record['confidence']:.2f})",
                    affected_nodes=[record['id']],
                    confidence=0.85,
                    priority="medium",
                    suggested_action=f"Validate and improve confidence for: {record['name']}"
                )
                gaps.append(gap)
        
        self.recent_gaps = gaps
        return gaps
    
    def check_duplicate_gap(self, gap: KnowledgeGap) -> bool:
        """Check if similar gap was already processed recently."""
        cutoff = datetime.now() - timedelta(hours=self.min_gap_age_hours)
        
        with self.driver.session() as session:
            result = session.run('''
                MATCH (g:KnowledgeGap)
                WHERE g.gap_type = $gap_type
                  AND g.detected_at > datetime($cutoff)
                  AND ANY(node_id IN g.affected_nodes WHERE node_id IN $affected_nodes)
                RETURN count(g) as count
            ''', 
                gap_type=gap.gap_type.value,
                cutoff=cutoff.isoformat(),
                affected_nodes=gap.affected_nodes
            )
            
            return result.single()['count'] > 0
    
    def gap_to_task(self, gap: KnowledgeGap) -> Optional[GeneratedTask]:
        """Convert a knowledge gap into a generated task."""
        
        # Map gap types to deliverable types and agents
        gap_mappings = {
            GapType.MISSING_DOCUMENTATION: (
                DeliverableType.RESEARCH,
                ["researcher", "writer"],
                "Document and research: {}"
            ),
            GapType.INCOMPLETE_RESEARCH: (
                DeliverableType.RESEARCH,
                ["researcher"],
                "Complete research on: {}"
            ),
            GapType.ORPHANED_CONCEPT: (
                DeliverableType.ANALYSIS,
                ["analyst", "researcher"],
                "Connect and contextualize: {}"
            ),
            GapType.UNCONNECTED_TOPIC: (
                DeliverableType.RESEARCH,
                ["researcher"],
                "Research topic connections: {}"
            ),
            GapType.OUTDATED_INFORMATION: (
                DeliverableType.RESEARCH,
                ["researcher"],
                "Update research: {}"
            ),
            GapType.CONTRADICTORY_DATA: (
                DeliverableType.ANALYSIS,
                ["analyst"],
                "Resolve contradictions in: {}"
            ),
            GapType.LOW_CONFIDENCE: (
                DeliverableType.ANALYSIS,
                ["analyst", "researcher"],
                "Validate and verify: {}"
            ),
            GapType.ACTIONABLE_FINDING: (
                DeliverableType.ANALYSIS,
                ["analyst"],
                "Act on finding: {}"
            ),
        }
        
        mapping = gap_mappings.get(gap.gap_type)
        if not mapping:
            return None
        
        deliverable_type, agents, title_template = mapping
        
        # Extract a clean name for the task
        name = gap.description.split("'")[1] if "'" in gap.description else "unknown"
        title = title_template.format(name)
        
        task = GeneratedTask(
            id=self.generate_task_id(),
            title=title,
            description=gap.suggested_action,
            deliverable_type=deliverable_type,
            priority=gap.priority,
            triggered_by=TaskTrigger.KNOWLEDGE_GAP_DETECTED,
            source_gap=gap,
            required_agents=agents,
            estimated_duration=30 if gap.priority == "high" else 15,
            context={"gap_type": gap.gap_type.value, "affected_nodes": gap.affected_nodes}
        )
        
        return task
    
    def generate_tasks_from_gaps(self, gaps: List[KnowledgeGap]) -> List[GeneratedTask]:
        """Generate tasks from detected knowledge gaps."""
        tasks = []
        
        for gap in gaps:
            # Skip if below confidence threshold
            if gap.confidence < self.confidence_threshold:
                continue
            
            # Skip if duplicate was recently processed
            if self.check_duplicate_gap(gap):
                continue
            
            task = self.gap_to_task(gap)
            if task:
                tasks.append(task)
        
        # Limit tasks per cycle
        return tasks[:self.max_tasks_per_cycle]
    
    def persist_gap(self, gap: KnowledgeGap) -> None:
        """Persist knowledge gap to Neo4j."""
        with self.driver.session() as session:
            session.run('''
                CREATE (g:KnowledgeGap {
                    id: $id,
                    gap_type: $gap_type,
                    description: $description,
                    affected_nodes: $affected_nodes,
                    confidence: $confidence,
                    priority: $priority,
                    suggested_action: $suggested_action,
                    detected_at: datetime($detected_at),
                    status: 'detected'
                })
            ''',
                id=f"gap_{hashlib.md5(gap.description.encode()).hexdigest()[:12]}",
                gap_type=gap.gap_type.value,
                description=gap.description,
                affected_nodes=gap.affected_nodes,
                confidence=gap.confidence,
                priority=gap.priority,
                suggested_action=gap.suggested_action,
                detected_at=gap.detected_at.isoformat()
            )
    
    def persist_task(self, task: GeneratedTask) -> bool:
        """Persist generated task to Neo4j."""
        try:
            with self.driver.session() as session:
                # Check for duplicate
                result = session.run('''
                    MATCH (t:Task)
                    WHERE t.title = $title
                      AND t.created_at > datetime() - duration('PT1H')
                    RETURN count(t) as count
                ''', title=task.title)
                
                if result.single()['count'] > 0:
                    return False  # Duplicate exists
                
                # Create task
                session.run('''
                    CREATE (t:Task {
                        id: $id,
                        type: 'dynamic',
                        title: $title,
                        description: $description,
                        status: 'pending',
                        priority: $priority,
                        priority_weight: $weight,
                        deliverable_type: $deliverable_type,
                        required_agents: $agents,
                        estimated_duration: $duration,
                        triggered_by: $triggered_by,
                        created_at: datetime(),
                        auto_generated: true
                    })
                ''',
                    id=task.id,
                    title=task.title,
                    description=task.description,
                    priority=task.priority,
                    weight=0.8 if task.priority == "high" else 0.5,
                    deliverable_type=task.deliverable_type.value,
                    agents=task.required_agents,
                    duration=task.estimated_duration,
                    triggered_by=task.triggered_by.value
                )
                
                # Link to source gap if exists
                if task.source_gap:
                    session.run('''
                        MATCH (t:Task {id: $task_id})
                        MATCH (g:KnowledgeGap {description: $gap_desc})
                        MERGE (t)-[:GENERATED_FROM]->(g)
                    ''', task_id=task.id, gap_desc=task.source_gap.description)
                
                return True
        except Exception as e:
            print(f"Error persisting task: {e}")
            return False
    
    def spawn_agents_for_task(self, task: GeneratedTask) -> Dict[str, Any]:
        """
        Spawn appropriate agents for a generated task.
        
        Returns spawn results for each agent.
        """
        results = {"spawned": [], "failed": []}
        
        try:
            # Import here to avoid circular dependency
            from kurultai.agent_spawner_direct import spawn_agent
            
            for agent_type in task.required_agents:
                try:
                    # Check if agent is already active
                    with self.driver.session() as session:
                        result = session.run('''
                            MATCH (a:Agent {type: $type})
                            WHERE a.status = 'active'
                              AND a.last_heartbeat > datetime() - duration('PT5M')
                            RETURN a.id as id
                            LIMIT 1
                        ''', type=agent_type)
                        
                        existing = result.single()
                        if existing:
                            results["spawned"].append({
                                "agent_type": agent_type,
                                "agent_id": existing['id'],
                                "status": "already_active"
                            })
                            continue
                    
                    # Spawn new agent
                    agent_id = spawn_agent(agent_type, task.context)
                    results["spawned"].append({
                        "agent_type": agent_type,
                        "agent_id": agent_id,
                        "status": "spawned"
                    })
                    
                except Exception as e:
                    results["failed"].append({
                        "agent_type": agent_type,
                        "error": str(e)
                    })
        
        except ImportError:
            results["error"] = "Agent spawner not available"
        
        return results
    
    async def run_generation_cycle(self) -> Dict[str, Any]:
        """
        Execute one full task generation cycle.
        
        Returns summary of actions taken.
        """
        cycle_start = datetime.now()
        summary = {
            "cycle_start": cycle_start.isoformat(),
            "gaps_detected": 0,
            "tasks_generated": 0,
            "tasks_persisted": 0,
            "agents_spawned": 0,
            "errors": []
        }
        
        try:
            # Step 1: Detect knowledge gaps
            gaps = self.detect_knowledge_gaps()
            summary["gaps_detected"] = len(gaps)
            
            # Step 2: Persist gaps
            for gap in gaps:
                self.persist_gap(gap)
            
            # Step 3: Generate tasks from gaps
            tasks = self.generate_tasks_from_gaps(gaps)
            summary["tasks_generated"] = len(tasks)
            
            # Step 4: Persist and spawn for each task
            for task in tasks:
                if self.persist_task(task):
                    summary["tasks_persisted"] += 1
                    
                    # Spawn agents if auto-assign enabled
                    if task.auto_assign:
                        spawn_results = self.spawn_agents_for_task(task)
                        summary["agents_spawned"] += len(spawn_results.get("spawned", []))
                        
                        # Update task with assigned agents
                        with self.driver.session() as session:
                            session.run('''
                                MATCH (t:Task {id: $task_id})
                                SET t.assigned_agents = $agents,
                                    t.spawned_at = datetime()
                            ''', task_id=task.id, agents=task.required_agents)
            
            # Step 5: Monitor research outputs for actionable items
            research_tasks = self.monitor_research_outputs()
            for task in research_tasks:
                if self.persist_task(task):
                    summary["tasks_persisted"] += 1
            
        except Exception as e:
            summary["errors"].append(str(e))
        
        summary["cycle_end"] = datetime.now().isoformat()
        self.generation_history.append(summary)
        
        return summary
    
    def monitor_research_outputs(self) -> List[GeneratedTask]:
        """
        Monitor recent research outputs for actionable findings.
        
        Looks for patterns like:
        - "TODO:" or "FIXME:" in research
        - Explicit action items
        - Gaps mentioned in research
        """
        tasks = []
        
        with self.driver.session() as session:
            # Find recent research with actionable content
            result = session.run('''
                MATCH (r:Research)
                WHERE r.created_at > datetime() - duration('PT24H')
                  AND (r.content CONTAINS 'TODO:' 
                       OR r.content CONTAINS 'FIXME:'
                       OR r.content CONTAINS 'ACTION ITEM'
                       OR r.content CONTAINS 'RECOMMENDATION:')
                RETURN r.id as id, r.topic as topic, 
                       r.content as content, r.created_at as created
                ORDER BY r.created_at DESC
                LIMIT 10
            ''')
            
            for record in result:
                # Parse for action items
                content = record['content']
                action_items = self._extract_action_items(content)
                
                for item in action_items:
                    task = GeneratedTask(
                        id=self.generate_task_id("action"),
                        title=f"Action from research: {record['topic']}",
                        description=item,
                        deliverable_type=DeliverableType.ANALYSIS,
                        priority="medium",
                        triggered_by=TaskTrigger.RESEARCH_COMPLETED,
                        required_agents=["analyst"],
                        context={"source_research": record['id']}
                    )
                    tasks.append(task)
        
        return tasks[:3]  # Limit to 3 action tasks per cycle
    
    def _extract_action_items(self, content: str) -> List[str]:
        """Extract action items from research content."""
        items = []
        
        # Look for TODO/FIXME patterns
        import re
        
        patterns = [
            r'TODO[:\s]+(.+?)(?:\n|$)',
            r'FIXME[:\s]+(.+?)(?:\n|$)',
            r'ACTION ITEM[:\s]+(.+?)(?:\n|$)',
            r'RECOMMENDATION[:\s]+(.+?)(?:\n|$)',
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, content, re.IGNORECASE)
            items.extend(matches)
        
        return items
    
    def get_generation_stats(self) -> Dict[str, Any]:
        """Get statistics about task generation."""
        with self.driver.session() as session:
            # Count auto-generated tasks
            result = session.run('''
                MATCH (t:Task)
                WHERE t.auto_generated = true
                RETURN count(t) as total,
                       count(CASE WHEN t.status = 'completed' THEN 1 END) as completed,
                       count(CASE WHEN t.status = 'pending' THEN 1 END) as pending
            ''')
            task_stats = result.single()
            
            # Count knowledge gaps
            result = session.run('''
                MATCH (g:KnowledgeGap)
                RETURN count(g) as total,
                       count(CASE WHEN g.status = 'addressed' THEN 1 END) as addressed
            ''')
            gap_stats = result.single()
        
        return {
            "tasks_generated_total": task_stats['total'],
            "tasks_completed": task_stats['completed'],
            "tasks_pending": task_stats['pending'],
            "gaps_detected_total": gap_stats['total'],
            "gaps_addressed": gap_stats['addressed'],
            "generation_cycles": len(self.generation_history)
        }


# Global instance
_generator: Optional[DynamicTaskGenerator] = None


def get_task_generator(driver) -> DynamicTaskGenerator:
    """Get or create global task generator instance."""
    global _generator
    if _generator is None:
        _generator = DynamicTaskGenerator(driver)
    return _generator


def reset_task_generator():
    """Reset global instance (for testing)."""
    global _generator
    _generator = None


# Standalone execution
if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Dynamic Task Generator")
    parser.add_argument("--cycle", action="store_true", help="Run one generation cycle")
    parser.add_argument("--stats", action="store_true", help="Show generation statistics")
    
    args = parser.parse_args()
    
    # Connect to Neo4j
    from neo4j import GraphDatabase
    
    uri = os.environ.get('NEO4J_URI', 'bolt://localhost:7687')
    password = os.environ.get('NEO4J_PASSWORD')
    
    if not password:
        print("NEO4J_PASSWORD not set")
        sys.exit(1)
    
    driver = GraphDatabase.driver(uri, auth=('neo4j', password))
    
    generator = get_task_generator(driver)
    
    if args.cycle:
        result = asyncio.run(generator.run_generation_cycle())
        print(json.dumps(result, indent=2))
    elif args.stats:
        print(json.dumps(generator.get_generation_stats(), indent=2))
    else:
        parser.print_help()
    
    driver.close()
